{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNj5mWdU6ackW7hfqR/QWDd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanika-sehgal123/Hometask2/blob/main/classification_modeltraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "# Upload the data.zip file\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "pnhFhScjrm_z",
        "outputId": "cdc8a1b7-04e1-41b9-e8a6-31d453883b53"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a711666f-28c2-4e62-87c2-c3747e98cc5f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a711666f-28c2-4e62-87c2-c3747e98cc5f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.zip to data (6).zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(\"data.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"data\")"
      ],
      "metadata": {
        "id": "tajcTrttsGCi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data\n",
        "!ls data/Priority\n",
        "!ls data/Stop\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUIolxFEsL3W",
        "outputId": "7744402d-64e6-403a-c1ea-6556d2e98d32"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Priority  Stop\n",
            "0054d8da-0ed5-11ef-88be-a46bb606fa86.jpg  570694be-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "012168c8-0ed5-11ef-88be-a46bb606fa86.jpg  5723d240-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "01f363d2-0ed5-11ef-88be-a46bb606fa86.jpg  57cfd84e-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "054bc47a-0ed5-11ef-88be-a46bb606fa86.jpg  59c12c14-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "0693a67c-0ed5-11ef-88be-a46bb606fa86.jpg  59d73f18-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "0729d336-0ed5-11ef-88be-a46bb606fa86.jpg  59ef2f38-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "0a394700-0ed5-11ef-88be-a46bb606fa86.jpg  5a0d84c4-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "0b91ea08-0ed5-11ef-88be-a46bb606fa86.jpg  5a48a784-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "0cc3e570-0ed5-11ef-88be-a46bb606fa86.jpg  5ad82f0a-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "210f1f14-0ed4-11ef-baef-a46bb606fa86.jpg  5b6f18b6-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "252b8efc-0ed4-11ef-baef-a46bb606fa86.jpg  5bf29c22-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "2607f05e-0ed4-11ef-baef-a46bb606fa86.jpg  5d754ea8-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "26bc297a-0ed4-11ef-baef-a46bb606fa86.jpg  5d93338c-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "2875552e-0ed5-11ef-88be-a46bb606fa86.jpg  5db13ae4-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "2a664faa-0ed5-11ef-88be-a46bb606fa86.jpg  5dff878a-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "2b14dc8c-0ed5-11ef-88be-a46bb606fa86.jpg  5e1fa8bc-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "2b504386-0ed4-11ef-baef-a46bb606fa86.jpg  5e3e1dd8-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "2da3467e-0ed4-11ef-baef-a46bb606fa86.jpg  5e5e5d3c-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "2f12a314-0ed5-11ef-88be-a46bb606fa86.jpg  5e9f50e4-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "2f6414ac-0ed4-11ef-baef-a46bb606fa86.jpg  5ebb8a02-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "301bb3c2-0ed5-11ef-88be-a46bb606fa86.jpg  5ec30266-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "30f7f238-0ed5-11ef-88be-a46bb606fa86.jpg  5edbc1a0-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "30fc78a4-0ed4-11ef-baef-a46bb606fa86.jpg  5f28b034-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "32381b10-0ed4-11ef-baef-a46bb606fa86.jpg  6311cee0-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "33626e68-0ed5-11ef-88be-a46bb606fa86.jpg  632cd3fc-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "336b266c-0ed4-11ef-baef-a46bb606fa86.jpg  6349d312-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "35a219a8-0ed5-11ef-88be-a46bb606fa86.jpg  637ec3ba-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "361e45b0-0ed4-11ef-baef-a46bb606fa86.jpg  63b82d8a-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "36bc2428-0ed5-11ef-88be-a46bb606fa86.jpg  63da9dca-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "3831719c-0ed4-11ef-baef-a46bb606fa86.jpg  64d80b5e-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "3b15ba26-0ed4-11ef-baef-a46bb606fa86.jpg  64f4f9e4-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "3d489354-0ed4-11ef-baef-a46bb606fa86.jpg  6513b6d6-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "3f9403ea-0ed5-11ef-88be-a46bb606fa86.jpg  652eb0e4-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "40403c96-0ed5-11ef-88be-a46bb606fa86.jpg  654d7dbc-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "41087846-0ed5-11ef-88be-a46bb606fa86.jpg  6d43ac6c-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4189d842-0ed4-11ef-baef-a46bb606fa86.jpg  6de8fdfc-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4202c332-0ed5-11ef-88be-a46bb606fa86.jpg  6df00428-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "42eb9716-0ed4-11ef-baef-a46bb606fa86.jpg  6e232478-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "447bbd0e-0ed4-11ef-baef-a46bb606fa86.jpg  6e3e2160-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "44c2557e-0ed5-11ef-88be-a46bb606fa86.jpg  6e5b7864-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "46048138-0ed4-11ef-baef-a46bb606fa86.jpg  6e774bde-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "467047a0-0ed5-11ef-88be-a46bb606fa86.jpg  6f93c48e-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4761b4a6-0ed4-11ef-baef-a46bb606fa86.jpg  7170c178-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "48297374-0ed4-11ef-baef-a46bb606fa86.jpg  733e8eca-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "48ce0858-0ed4-11ef-baef-a46bb606fa86.jpg  735a80e4-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4926645c-0ed5-11ef-88be-a46bb606fa86.jpg  737589d4-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4a37e7bc-0ed5-11ef-88be-a46bb606fa86.jpg  739409ae-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4c882938-0ed4-11ef-baef-a46bb606fa86.jpg  73b3feda-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4d33b87e-0ed5-11ef-88be-a46bb606fa86.jpg  73ed384e-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4d6ef552-0ed4-11ef-baef-a46bb606fa86.jpg  740a4182-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4e14b6a6-ed9a-11ed-b020-a46bb6069316.jpg  75f4936c-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4e332474-ed9a-11ed-b020-a46bb6069316.jpg  76893b0c-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4e4bb80e-ed9a-11ed-b020-a46bb6069316.jpg  76a4f25c-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4e6c0654-ed9a-11ed-b020-a46bb6069316.jpg  76c37cc2-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4ea8574e-ed9a-11ed-b020-a46bb6069316.jpg  7721d9b6-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4ec80c56-ed9a-11ed-b020-a46bb6069316.jpg  77406afc-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4f02c594-ed9a-11ed-b020-a46bb6069316.jpg  779482cc-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "4f21545a-ed9a-11ed-b020-a46bb6069316.jpg  78452cdc-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "4f3e11d0-ed9a-11ed-b020-a46bb6069316.jpg  78e7076e-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "50b3922c-0ed4-11ef-baef-a46bb606fa86.jpg  78f9d446-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "51f24806-ed9a-11ed-b020-a46bb6069316.jpg  792e53c4-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "51f741e2-0ed4-11ef-baef-a46bb606fa86.jpg  794ab15e-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "520d5b28-ed9a-11ed-b020-a46bb6069316.jpg  79eb7184-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "524928ce-ed9a-11ed-b020-a46bb6069316.jpg  7a0679e8-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "52635f32-ed9a-11ed-b020-a46bb6069316.jpg  7a5a8434-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "5280c180-ed9a-11ed-b020-a46bb6069316.jpg  7aa61f66-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "529ae7f4-ed9a-11ed-b020-a46bb6069316.jpg  7af026e4-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "52db41d4-0ed5-11ef-88be-a46bb606fa86.jpg  7bb8ff60-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "537a6da4-0ed5-11ef-88be-a46bb606fa86.jpg  7ed5a3e2-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "54599b64-0ed5-11ef-88be-a46bb606fa86.jpg  7f59161e-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "54ddba6c-0ed4-11ef-baef-a46bb606fa86.jpg  7fcebad6-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "558e7d7a-0ed4-11ef-baef-a46bb606fa86.jpg  822cdeca-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "565656ee-ed9a-11ed-b020-a46bb6069316.jpg  83884034-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "56721ef6-ed9a-11ed-b020-a46bb6069316.jpg  84b93aee-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "568ccec2-ed9a-11ed-b020-a46bb6069316.jpg  85d033e2-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "56ad5c1e-ed9a-11ed-b020-a46bb6069316.jpg  86e9ea3e-0ed5-11ef-88be-a46bb606fa86.jpg\n",
            "56cbe936-ed9a-11ed-b020-a46bb6069316.jpg\n",
            "001066ca-ed96-11ed-926d-a46bb6069316.jpg  9c8644ac-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "0034f8d2-ed96-11ed-926d-a46bb6069316.jpg  9cbb82de-ed96-11ed-926d-a46bb6069316.jpg\n",
            "01b6dbb6-0ed4-11ef-baef-a46bb606fa86.jpg  9cd299fc-ed95-11ed-926d-a46bb6069316.jpg\n",
            "030c05e0-0ed4-11ef-baef-a46bb606fa86.jpg  9eb7bd92-ed95-11ed-926d-a46bb6069316.jpg\n",
            "04807808-ed96-11ed-926d-a46bb6069316.jpg  a14b7a52-ed96-11ed-926d-a46bb6069316.jpg\n",
            "04ec56ae-ed96-11ed-926d-a46bb6069316.jpg  a3aa19f2-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "050b5cfc-ed96-11ed-926d-a46bb6069316.jpg  a606ad50-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "052e633c-ed96-11ed-926d-a46bb6069316.jpg  a60d0782-ed95-11ed-926d-a46bb6069316.jpg\n",
            "054d74c0-ed96-11ed-926d-a46bb6069316.jpg  a6794838-ed96-11ed-926d-a46bb6069316.jpg\n",
            "05711164-ed96-11ed-926d-a46bb6069316.jpg  a7a25f5c-ed95-11ed-926d-a46bb6069316.jpg\n",
            "058efdf0-ed96-11ed-926d-a46bb6069316.jpg  a81b1cfc-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "05b5285e-ed96-11ed-926d-a46bb6069316.jpg  a8f48b90-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "05eae340-ed96-11ed-926d-a46bb6069316.jpg  a9248fe4-ed95-11ed-926d-a46bb6069316.jpg\n",
            "079e2f16-0ed4-11ef-baef-a46bb606fa86.jpg  ab01419e-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "0844f7f6-0ed4-11ef-baef-a46bb606fa86.jpg  ab575c9c-ed95-11ed-926d-a46bb6069316.jpg\n",
            "09eac7c0-0ed4-11ef-baef-a46bb606fa86.jpg  acd87618-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "0a27272a-ed96-11ed-926d-a46bb6069316.jpg  ad3aa654-ed95-11ed-926d-a46bb6069316.jpg\n",
            "0a59dcc4-ed96-11ed-926d-a46bb6069316.jpg  adcd3ae0-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "0ab99a88-ed96-11ed-926d-a46bb6069316.jpg  aef38fb0-ed95-11ed-926d-a46bb6069316.jpg\n",
            "0b21739c-ed96-11ed-926d-a46bb6069316.jpg  b12e528c-ed96-11ed-926d-a46bb6069316.jpg\n",
            "0b7dcfb6-ed96-11ed-926d-a46bb6069316.jpg  b1928b36-ed95-11ed-926d-a46bb6069316.jpg\n",
            "0b919b62-0ed4-11ef-baef-a46bb606fa86.jpg  b1d0a05a-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "0babca06-ed96-11ed-926d-a46bb6069316.jpg  b2766a80-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "0e9141f6-ed96-11ed-926d-a46bb6069316.jpg  b3b3fe2c-ed95-11ed-926d-a46bb6069316.jpg\n",
            "0ebe0b3c-ed96-11ed-926d-a46bb6069316.jpg  b52c56e0-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "0f0b56da-ed96-11ed-926d-a46bb6069316.jpg  b5a06676-ed95-11ed-926d-a46bb6069316.jpg\n",
            "0f3694e4-ed96-11ed-926d-a46bb6069316.jpg  b6555436-ed96-11ed-926d-a46bb6069316.jpg\n",
            "0f404fc4-0ed4-11ef-baef-a46bb606fa86.jpg  b82fe7e0-ed95-11ed-926d-a46bb6069316.jpg\n",
            "0f95250e-ed96-11ed-926d-a46bb6069316.jpg  bb586438-ed95-11ed-926d-a46bb6069316.jpg\n",
            "0fed7d30-ed96-11ed-926d-a46bb6069316.jpg  be25662a-ed95-11ed-926d-a46bb6069316.jpg\n",
            "10165174-ed96-11ed-926d-a46bb6069316.jpg  bf82c854-ed96-11ed-926d-a46bb6069316.jpg\n",
            "104bf392-ed96-11ed-926d-a46bb6069316.jpg  bff158be-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "129bf03e-ed96-11ed-926d-a46bb6069316.jpg  c0558b78-ed95-11ed-926d-a46bb6069316.jpg\n",
            "12c13b14-ed96-11ed-926d-a46bb6069316.jpg  c39a3bde-ed96-11ed-926d-a46bb6069316.jpg\n",
            "12e8ed9e-ed96-11ed-926d-a46bb6069316.jpg  c4290828-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "131284ce-ed96-11ed-926d-a46bb6069316.jpg  c57574a0-ed96-11ed-926d-a46bb6069316.jpg\n",
            "1338fc58-ed96-11ed-926d-a46bb6069316.jpg  c638bc58-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "136f7fe4-ed96-11ed-926d-a46bb6069316.jpg  c7cc1f4c-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "13864058-ed96-11ed-926d-a46bb6069316.jpg  c7eb7f22-ed96-11ed-926d-a46bb6069316.jpg\n",
            "151f4ef0-ed96-11ed-926d-a46bb6069316.jpg  cb2a909c-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "154500e6-ed96-11ed-926d-a46bb6069316.jpg  cb6c6cc0-ed95-11ed-926d-a46bb6069316.jpg\n",
            "156e956e-ed96-11ed-926d-a46bb6069316.jpg  cb74de68-ed96-11ed-926d-a46bb6069316.jpg\n",
            "15a368b0-0ed4-11ef-baef-a46bb606fa86.jpg  cd1926da-ed95-11ed-926d-a46bb6069316.jpg\n",
            "15e59506-ed96-11ed-926d-a46bb6069316.jpg  cd46f208-ed96-11ed-926d-a46bb6069316.jpg\n",
            "16188312-ed96-11ed-926d-a46bb6069316.jpg  cda76962-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "1644904c-ed96-11ed-926d-a46bb6069316.jpg  ceb5cb2e-ed95-11ed-926d-a46bb6069316.jpg\n",
            "17f0b362-ed96-11ed-926d-a46bb6069316.jpg  cedaca50-ed95-11ed-926d-a46bb6069316.jpg\n",
            "181c03aa-ed96-11ed-926d-a46bb6069316.jpg  cf19b232-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "20db95dc-ed96-11ed-926d-a46bb6069316.jpg  cf4b4928-ed96-11ed-926d-a46bb6069316.jpg\n",
            "2116b3b0-ed96-11ed-926d-a46bb6069316.jpg  d16d73d4-ed96-11ed-926d-a46bb6069316.jpg\n",
            "21438322-ed96-11ed-926d-a46bb6069316.jpg  d2b6da3c-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "215f1588-ed96-11ed-926d-a46bb6069316.jpg  d3951180-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "21809dd4-ed96-11ed-926d-a46bb6069316.jpg  d46dc764-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "219c9e76-ed96-11ed-926d-a46bb6069316.jpg  d472b018-ed95-11ed-926d-a46bb6069316.jpg\n",
            "21bf0808-ed96-11ed-926d-a46bb6069316.jpg  d52d2a4c-ed95-11ed-926d-a46bb6069316.jpg\n",
            "232855f0-ed96-11ed-926d-a46bb6069316.jpg  d5517898-ed95-11ed-926d-a46bb6069316.jpg\n",
            "23445822-ed96-11ed-926d-a46bb6069316.jpg  d570dd8c-ed95-11ed-926d-a46bb6069316.jpg\n",
            "2357baac-ed96-11ed-926d-a46bb6069316.jpg  d59775c8-ed95-11ed-926d-a46bb6069316.jpg\n",
            "237a00d0-ed96-11ed-926d-a46bb6069316.jpg  d5af66a6-ed95-11ed-926d-a46bb6069316.jpg\n",
            "239637dc-ed96-11ed-926d-a46bb6069316.jpg  d5cf74fa-ed95-11ed-926d-a46bb6069316.jpg\n",
            "3aa3659e-ed96-11ed-926d-a46bb6069316.jpg  d5e7b6d2-ed95-11ed-926d-a46bb6069316.jpg\n",
            "3ad41f54-ed96-11ed-926d-a46bb6069316.jpg  d634141e-ed95-11ed-926d-a46bb6069316.jpg\n",
            "3b03074c-ed96-11ed-926d-a46bb6069316.jpg  d7df3cd4-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "3b0d24de-ed96-11ed-926d-a46bb6069316.jpg  da390424-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "3b4aafa2-ed96-11ed-926d-a46bb6069316.jpg  dbb7284a-ed95-11ed-926d-a46bb6069316.jpg\n",
            "3b6be938-ed96-11ed-926d-a46bb6069316.jpg  dbc00fdc-ed95-11ed-926d-a46bb6069316.jpg\n",
            "3bdb0b10-ed96-11ed-926d-a46bb6069316.jpg  dc14a948-ed95-11ed-926d-a46bb6069316.jpg\n",
            "3bf7dbc8-ed96-11ed-926d-a46bb6069316.jpg  ddc145b2-ed95-11ed-926d-a46bb6069316.jpg\n",
            "4c6e2728-ed96-11ed-926d-a46bb6069316.jpg  ddc794b6-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "4e174cf8-ed96-11ed-926d-a46bb6069316.jpg  de36e966-ed95-11ed-926d-a46bb6069316.jpg\n",
            "4e341568-ed96-11ed-926d-a46bb6069316.jpg  de86663a-ed95-11ed-926d-a46bb6069316.jpg\n",
            "4e5278c8-ed96-11ed-926d-a46bb6069316.jpg  dea22870-ed95-11ed-926d-a46bb6069316.jpg\n",
            "4e987512-ed96-11ed-926d-a46bb6069316.jpg  e2d97b0e-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "4ed4217a-ed96-11ed-926d-a46bb6069316.jpg  e4a72940-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "4f3748cc-ed96-11ed-926d-a46bb6069316.jpg  e53c90ac-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "4f9d690e-ed96-11ed-926d-a46bb6069316.jpg  e68776fc-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "53addfd8-ed96-11ed-926d-a46bb6069316.jpg  e954d8d0-ed95-11ed-926d-a46bb6069316.jpg\n",
            "53d431ba-ed96-11ed-926d-a46bb6069316.jpg  eba616f8-ed95-11ed-926d-a46bb6069316.jpg\n",
            "5496e5de-ed96-11ed-926d-a46bb6069316.jpg  ebce1388-ed95-11ed-926d-a46bb6069316.jpg\n",
            "54e0d54a-ed96-11ed-926d-a46bb6069316.jpg  ec19e7f4-ed95-11ed-926d-a46bb6069316.jpg\n",
            "550443c2-ed96-11ed-926d-a46bb6069316.jpg  ec426eae-ed95-11ed-926d-a46bb6069316.jpg\n",
            "552514bc-ed96-11ed-926d-a46bb6069316.jpg  ec7b93f0-ed95-11ed-926d-a46bb6069316.jpg\n",
            "55481606-ed96-11ed-926d-a46bb6069316.jpg  ecd41caa-ed95-11ed-926d-a46bb6069316.jpg\n",
            "5569c184-ed96-11ed-926d-a46bb6069316.jpg  ecf0b716-ed95-11ed-926d-a46bb6069316.jpg\n",
            "558ee374-ed96-11ed-926d-a46bb6069316.jpg  ed97243e-ed95-11ed-926d-a46bb6069316.jpg\n",
            "55bb3596-ed96-11ed-926d-a46bb6069316.jpg  edbbefd0-ed95-11ed-926d-a46bb6069316.jpg\n",
            "55f676ce-ed96-11ed-926d-a46bb6069316.jpg  ede8a60a-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "59c19608-ed96-11ed-926d-a46bb6069316.jpg  ee0943a2-ed95-11ed-926d-a46bb6069316.jpg\n",
            "5acb250a-ed96-11ed-926d-a46bb6069316.jpg  ee32eb44-ed95-11ed-926d-a46bb6069316.jpg\n",
            "5b2e05da-ed96-11ed-926d-a46bb6069316.jpg  eeb6d8b4-ed95-11ed-926d-a46bb6069316.jpg\n",
            "5b523b4e-ed96-11ed-926d-a46bb6069316.jpg  ef108576-ed95-11ed-926d-a46bb6069316.jpg\n",
            "5b7493d8-ed96-11ed-926d-a46bb6069316.jpg  ef467208-ed95-11ed-926d-a46bb6069316.jpg\n",
            "61ee9aa6-ed96-11ed-926d-a46bb6069316.jpg  f14bed12-ed95-11ed-926d-a46bb6069316.jpg\n",
            "633e2dae-ed96-11ed-926d-a46bb6069316.jpg  f19bca52-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "635c54c8-ed96-11ed-926d-a46bb6069316.jpg  f246865a-ed95-11ed-926d-a46bb6069316.jpg\n",
            "63993cbc-ed96-11ed-926d-a46bb6069316.jpg  f2cb0a28-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "63b988be-ed96-11ed-926d-a46bb6069316.jpg  f2e2eba8-ed95-11ed-926d-a46bb6069316.jpg\n",
            "63d92f70-ed96-11ed-926d-a46bb6069316.jpg  f3285f76-ed95-11ed-926d-a46bb6069316.jpg\n",
            "6433694a-ed96-11ed-926d-a46bb6069316.jpg  f35ed344-ed95-11ed-926d-a46bb6069316.jpg\n",
            "6445fd44-ed96-11ed-926d-a46bb6069316.jpg  f3ccc430-ed95-11ed-926d-a46bb6069316.jpg\n",
            "6461ef7c-ed96-11ed-926d-a46bb6069316.jpg  f3f9e578-ed95-11ed-926d-a46bb6069316.jpg\n",
            "85268ccc-ed96-11ed-926d-a46bb6069316.jpg  f4273f96-ed95-11ed-926d-a46bb6069316.jpg\n",
            "8778a588-ed95-11ed-926d-a46bb6069316.jpg  f44f3276-ed95-11ed-926d-a46bb6069316.jpg\n",
            "88fcf908-ed96-11ed-926d-a46bb6069316.jpg  f4906638-ed95-11ed-926d-a46bb6069316.jpg\n",
            "8dd26846-ed96-11ed-926d-a46bb6069316.jpg  f6e86a06-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "912e885e-ed95-11ed-926d-a46bb6069316.jpg  f92432a0-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "9248bc5e-0ed3-11ef-baef-a46bb606fa86.jpg  fa8027c6-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "93495448-ed95-11ed-926d-a46bb6069316.jpg  fbb69f4e-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "95608cec-ed95-11ed-926d-a46bb6069316.jpg  ff5b1b98-0ed3-11ef-baef-a46bb606fa86.jpg\n",
            "964d5792-0ed3-11ef-baef-a46bb606fa86.jpg  ff8bc96a-ed95-11ed-926d-a46bb6069316.jpg\n",
            "973654de-ed95-11ed-926d-a46bb6069316.jpg  ffb67188-ed95-11ed-926d-a46bb6069316.jpg\n",
            "9899dd18-0ed3-11ef-baef-a46bb606fa86.jpg  fff5303a-ed95-11ed-926d-a46bb6069316.jpg\n",
            "9912daac-ed95-11ed-926d-a46bb6069316.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Necessary Libraries\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Import Libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import os\n",
        "import zipfile\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "# Data Preparation\n",
        "data_dir = 'data'  # Main directory containing Priority and Stop subdirectories\n",
        "\n",
        "# Define transforms for training and validation sets\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Create a custom dataset loader\n",
        "def create_datasets(data_dir, transform, val_split=0.2):\n",
        "    full_dataset = datasets.ImageFolder(data_dir, transform)\n",
        "    dataset_size = len(full_dataset)\n",
        "    val_size = int(dataset_size * val_split)\n",
        "    train_size = dataset_size - val_size\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "# Create datasets\n",
        "train_dataset, val_dataset = create_datasets(data_dir, data_transforms['train'], val_split=0.2)\n",
        "\n",
        "# Create dataloaders\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4),\n",
        "    'val': DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "}\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train': len(train_dataset),\n",
        "    'val': len(val_dataset)\n",
        "}\n",
        "\n",
        "class_names = train_dataset.dataset.classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the Model\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# Train ResNet18\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "num_ftrs = resnet18.fc.in_features\n",
        "resnet18.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_resnet = optim.SGD(resnet18.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_resnet, step_size=7, gamma=0.1)\n",
        "\n",
        "resnet18 = train_model(resnet18, criterion, optimizer_resnet, exp_lr_scheduler, num_epochs=25)\n",
        "\n",
        "# Train MobileNetV3\n",
        "mobilenet_v3 = models.mobilenet_v3_large(pretrained=True)\n",
        "num_ftrs = mobilenet_v3.classifier[3].in_features\n",
        "mobilenet_v3.classifier[3] = nn.Linear(num_ftrs, len(class_names))\n",
        "mobilenet_v3 = mobilenet_v3.to(device)\n",
        "\n",
        "optimizer_mobilenet = optim.SGD(mobilenet_v3.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_mobilenet, step_size=7, gamma=0.1)\n",
        "\n",
        "mobilenet_v3 = train_model(mobilenet_v3, criterion, optimizer_mobilenet, exp_lr_scheduler, num_epochs=25)\n",
        "\n",
        "# Save the Models\n",
        "torch.save(resnet18.state_dict(), 'resnet18_stop_priority.pth')\n",
        "torch.save(mobilenet_v3.state_dict(), 'mobilenet_v3_stop_priority.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K3mEkkIJtQ22",
        "outputId": "c1563569-b08d-44df-b4d0-dcbe07c31fd7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 67.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5781 Acc: 0.7195\n",
            "val Loss: 0.4499 Acc: 0.8533\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.3094 Acc: 0.9241\n",
            "val Loss: 0.2107 Acc: 0.9067\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.1567 Acc: 0.9604\n",
            "val Loss: 0.1727 Acc: 0.8933\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.1018 Acc: 0.9736\n",
            "val Loss: 0.1214 Acc: 0.9333\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.0639 Acc: 0.9967\n",
            "val Loss: 0.0673 Acc: 1.0000\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.0477 Acc: 0.9967\n",
            "val Loss: 0.0623 Acc: 0.9733\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.0291 Acc: 1.0000\n",
            "val Loss: 0.0408 Acc: 1.0000\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.0314 Acc: 1.0000\n",
            "val Loss: 0.0458 Acc: 1.0000\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.0290 Acc: 0.9967\n",
            "val Loss: 0.0434 Acc: 1.0000\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.0322 Acc: 1.0000\n",
            "val Loss: 0.0472 Acc: 1.0000\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.0324 Acc: 0.9967\n",
            "val Loss: 0.0517 Acc: 0.9867\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.0265 Acc: 0.9967\n",
            "val Loss: 0.0460 Acc: 1.0000\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.0245 Acc: 1.0000\n",
            "val Loss: 0.0289 Acc: 1.0000\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.0235 Acc: 1.0000\n",
            "val Loss: 0.0390 Acc: 1.0000\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.0266 Acc: 1.0000\n",
            "val Loss: 0.0339 Acc: 1.0000\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.0287 Acc: 0.9967\n",
            "val Loss: 0.0413 Acc: 1.0000\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.0229 Acc: 1.0000\n",
            "val Loss: 0.0427 Acc: 1.0000\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.0263 Acc: 0.9967\n",
            "val Loss: 0.0480 Acc: 1.0000\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.0339 Acc: 0.9967\n",
            "val Loss: 0.0462 Acc: 1.0000\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.0272 Acc: 1.0000\n",
            "val Loss: 0.0403 Acc: 1.0000\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.0302 Acc: 1.0000\n",
            "val Loss: 0.0411 Acc: 1.0000\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.0240 Acc: 1.0000\n",
            "val Loss: 0.0384 Acc: 1.0000\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.0240 Acc: 0.9967\n",
            "val Loss: 0.0434 Acc: 1.0000\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.0240 Acc: 0.9967\n",
            "val Loss: 0.0445 Acc: 1.0000\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.0257 Acc: 0.9967\n",
            "val Loss: 0.0347 Acc: 1.0000\n",
            "\n",
            "Best val Acc: 1.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 65.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-4f652f2c1f82>\u001b[0m in \u001b[0;36m<cell line: 137>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_mobilenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0mmobilenet_v3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmobilenet_v3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_mobilenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;31m# Save the Models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-4f652f2c1f82>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "J8ykt9DavH3N"
      }
    }
  ]
}